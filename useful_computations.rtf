{\rtf1\ansi\ansicpg1252\cocoartf1504\cocoasubrtf830
{\fonttbl\f0\fswiss\fcharset0 ArialMT;}
{\colortbl;\red255\green255\blue255;\red26\green26\blue26;\red255\green255\blue255;}
{\*\expandedcolortbl;;\cssrgb\c13333\c13333\c13333;\cssrgb\c100000\c100000\c100000;}
\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\deftab720
\pard\pardeftab720\sl300\partightenfactor0

\f0\fs25\fsmilli12800 \cf2 \cb3 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 def loss_function(X,Y, w, alpha=0):\cb1 \
\cb3 \'a0 \'a0 n_classes = Y.shape[1]\cb1 \
\cb3 \'a0 \'a0 n_features = X.shape[1]\cb1 \
\cb3 \'a0 \'a0 w = w.reshape(n_classes, -1)\cb1 \
\cb3 \'a0 \'a0 fit_intercept = w.size == (n_classes * (n_features + 1))\cb1 \
\cb3 \'a0 \'a0 old_w = w.copy()\cb1 \
\cb3 \'a0 \'a0 if fit_intercept:\cb1 \
\cb3 \'a0 \'a0 \'a0 \'a0 intercept = w[:, -1]\cb1 \
\cb3 \'a0 \'a0 \'a0 \'a0 w = w[:, :-1]\cb1 \
\cb3 \'a0 \'a0 else:\cb1 \
\cb3 \'a0 \'a0 \'a0 \'a0 intercept = 0\cb1 \
\cb3 \'a0 \'a0 p = safe_sparse_dot(X, w.T)\cb1 \
\cb3 \'a0 \'a0 p += intercept\cb1 \
\cb3 \'a0 \'a0 p -= logsumexp(p, axis=1)[:, np.newaxis]\cb1 \
\cb3 \'a0 \'a0 loss = -(Y * p).sum()\cb1 \
\cb3 \'a0 \'a0 loss += 0.5 * alpha * squared_norm(w)\cb1 \
\cb3 \'a0 \'a0 p = np.exp(p, p)\cb1 \
\cb3 \'a0 \'a0 return loss, p, w\cb1 \
\
\cb3 def grad_loss(X, Y, w, alpha=0):\cb1 \
\cb3 \'a0 \'a0 n_classes = Y.shape[1]\cb1 \
\cb3 \'a0 \'a0 n_features = X.shape[1]\cb1 \
\cb3 \'a0 \'a0 fit_intercept = (w.size == n_classes * (n_features + 1))\cb1 \
\cb3 \'a0 \'a0 grad = np.zeros((n_classes, n_features + bool(fit_intercept)),\cb1 \
\cb3 \'a0 \'a0 \'a0 \'a0 \'a0 \'a0 \'a0 \'a0 \'a0 \'a0 dtype=X.dtype)\cb1 \
\cb3 \'a0 \'a0 loss, p, w = loss_function(X, Y, w,alpha)\cb1 \
\cb3 \'a0 \'a0 diff = (p - Y)\cb1 \
\cb3 \'a0 \'a0 grad[:, :n_features] = safe_sparse_dot(diff.T, X)\cb1 \
\cb3 \'a0 \'a0 grad[:, :n_features] += alpha * w\cb1 \
\cb3 \'a0 \'a0 if fit_intercept:\cb1 \
\cb3 \'a0 \'a0 \'a0 \'a0 grad[:, -1] = diff.sum(axis=0)\cb1 \
\cb3 \'a0 \'a0 return loss, grad.ravel(), p\cb1 \
\
\cb3 def hessian_loss(X, Y, w, alpha=0):\cb1 \
\cb3 \'a0 \'a0 n_features = X.shape[1]\cb1 \
\cb3 \'a0 \'a0 n_classes = Y.shape[1]\cb1 \
\cb3 \'a0 \'a0 fit_intercept = w.size == (n_classes * (n_features + 1))\cb1 \
\
\cb3 \'a0 \'a0 loss, grad, p = grad_loss(X, Y, w,alpha)\cb1 \
\cb3 \'a0 \'a0 def hessp(v):\cb1 \
\cb3 \'a0 \'a0 \'a0 \'a0 v = v.reshape(n_classes, -1)\cb1 \
\cb3 \'a0 \'a0 \'a0 \'a0 if fit_intercept:\cb1 \
\cb3 \'a0 \'a0 \'a0 \'a0 \'a0 \'a0 inter_terms = v[:, -1]\cb1 \
\cb3 \'a0 \'a0 \'a0 \'a0 \'a0 \'a0 v = v[:, :-1]\cb1 \
\cb3 \'a0 \'a0 \'a0 \'a0 else:\cb1 \
\cb3 \'a0 \'a0 \'a0 \'a0 \'a0 \'a0 inter_terms = 0\cb1 \
\cb3 \'a0 \'a0 \'a0 \'a0 r_yhat = safe_sparse_dot(X, v.T)\cb1 \
\cb3 \'a0 \'a0 \'a0 \'a0 r_yhat += inter_terms\cb1 \
\cb3 \'a0 \'a0 \'a0 \'a0 r_yhat += (-p * r_yhat).sum(axis=1)[:, np.newaxis]\cb1 \
\cb3 \'a0 \'a0 \'a0 \'a0 r_yhat *= p\cb1 \
\cb3 \'a0 \'a0 \'a0 \'a0 hessProd = np.zeros((n_classes, n_features + bool(fit_intercept)))\cb1 \
\cb3 \'a0 \'a0 \'a0 \'a0 hessProd[:, :n_features] = safe_sparse_dot(r_yhat.T, X)\cb1 \
\cb3 \'a0 \'a0 \'a0 \'a0 hessProd[:, :n_features] += v * alpha\cb1 \
\cb3 \'a0 \'a0 \'a0 \'a0 if fit_intercept:\cb1 \
\cb3 \'a0 \'a0 \'a0 \'a0 \'a0 \'a0 hessProd[:, -1] = r_yhat.sum(axis=0)\cb1 \
\cb3 \'a0 \'a0 \'a0 \'a0 return hessProd.ravel()\cb1 \
\cb3 \'a0 \'a0 w_copy = w.copy()\cb1 \
\cb3 \'a0 \'a0 w_copy[-1] = 0.0\cb1 \
\cb3 \'a0 \'a0 return grad, hessp, w_copy\cb1 \
}